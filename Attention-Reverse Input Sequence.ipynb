{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KksSPlLgU7y2",
        "outputId": "836fb00f-7d40-43b7-b5fc-3d94b08b8c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.3.0+cu121\n",
            "Uninstalling torch-2.3.0+cu121:\n",
            "  Successfully uninstalled torch-2.3.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ei9_vo6VEH2",
        "outputId": "95dc7c70-eeed-4b77-ea46-e8557300ae1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.7-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.7 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxp0tskDecQy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gLhqBBagVqkM",
        "outputId": "ce57a299-e758-45f6-d88b-54e64322c233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu117'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledDotProdAttention(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "      super(ScaledDotProdAttention, self).__init__()\n",
        "\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "\n",
        "        attention_scores = torch.matmul(query, key.transpose(-2,-1)) / np.sqrt(query.size(-1))\n",
        "\n",
        "        if mask is not None:\n",
        "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        attention = self.dropout(attention)\n",
        "\n",
        "        return torch.matmul(attention, value), attention\n"
      ],
      "metadata": {
        "id": "wo8NWO1WsLvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_k = d_model // nhead\n",
        "        self.d_v = d_model // nhead\n",
        "\n",
        "        self.linear_q = nn.Linear(d_model, d_model)\n",
        "        self.linear_k = nn.Linear(d_model, d_model)\n",
        "        self.linear_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "\n",
        "        self.scaled_dot_prod_attention = ScaledDotProdAttention(dropout)\n",
        "\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask=None, key_padding_mask=None):\n",
        "\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        query = self.linear_q(query).view(batch_size, -1, self.nhead, self.d_k).transpose(1,2)\n",
        "        key = self.linear_q(key).view(batch_size, -1, self.nhead, self.d_k).transpose(1,2)\n",
        "        value = self.linear_q(value).view(batch_size, -1, self.nhead, self.d_v).transpose(1,2)\n",
        "\n",
        "        output, attention_scores = self.scaled_dot_prod_attention(query, key, value)\n",
        "\n",
        "        output_concat = output.transpose(1,2).contiguous().view(batch_size, -1, self.d_model)\n",
        "\n",
        "        output_concat = self.linear_layer(output_concat)\n",
        "\n",
        "        return self.dropout(output_concat)"
      ],
      "metadata": {
        "id": "jUg3hEjNu-VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0,d_model,2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0,1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "EPJ5nDovyfT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_mlp=1024, dropout=0.1):\n",
        "        super(PoswiseFeedForward, self).__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_mlp)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_mlp, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = self.linear_1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.linear_2(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "R3eTyseV2iVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model, eps=1e-5):\n",
        "        super(LayerNorm, self).__init__()\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      mean = x.mean(dim=-1, keepdim=True)\n",
        "      std = x.std(dim=-1, keepdim=True)\n",
        "\n",
        "      x = (x - mean) / (std + self.eps)\n",
        "      x = self.gamma * x + self.beta\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "1UKS-WHw3axJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, nhead, d_mlp, dropout=0.1):\n",
        "      super(EncoderBlock, self).__init__()\n",
        "\n",
        "\n",
        "      self.multi_head_attention = MultiHeadAttention(d_model, nhead, dropout)\n",
        "\n",
        "      self.feed_forward = PoswiseFeedForward(d_model, d_mlp, dropout)\n",
        "\n",
        "      self.layer_norm1 = LayerNorm(d_model)\n",
        "      self.layer_norm2 = LayerNorm(d_model)\n",
        "\n",
        "      self.dropout1 = nn.Dropout(dropout)\n",
        "      self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
        "\n",
        "        x2 = self.multi_head_attention(x, x, x, mask=src_mask, key_padding_mask=src_key_padding_mask)[0]\n",
        "\n",
        "        x2 = self.layer_norm1(x2)\n",
        "\n",
        "        x = x + self.dropout1(x2)\n",
        "\n",
        "        x2 = self.feed_forward(x)\n",
        "\n",
        "        x2 = self.layer_norm2(x2)\n",
        "\n",
        "        x = x + self.dropout2(x2)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "DOH3i1cl4kzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, nhead, d_mlp, dropout=0.1):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "\n",
        "        self.masked_multi_head_attention = MultiHeadAttention(d_model, nhead, dropout)\n",
        "        self.multi_head_attention = MultiHeadAttention(d_model, nhead, dropout)\n",
        "\n",
        "        self.feed_forward = PoswiseFeedForward(d_model, d_mlp, dropout)\n",
        "\n",
        "        self.layer_norm1 = LayerNorm(d_model)\n",
        "        self.layer_norm2 = LayerNorm(d_model)\n",
        "        self.layer_norm3 = LayerNorm(d_model)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "\n",
        "        tgt2 = self.masked_multi_head_attention(tgt,tgt,tgt, mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)[0]\n",
        "\n",
        "        tgt2 = self.layer_norm1(tgt2)\n",
        "\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "\n",
        "        tgt2 = self.multi_head_attention(tgt2, memory, memory, mask=memory_mask, key_padding_mask=memory_key_padding_mask)[0]\n",
        "\n",
        "        tgt2 = self.layer_norm2(tgt2)\n",
        "\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "\n",
        "        tgt2 = self.feed_forward(tgt)\n",
        "\n",
        "        tgt2 = self.layer_norm3(tgt2)\n",
        "\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "\n",
        "        return tgt\n",
        "\n"
      ],
      "metadata": {
        "id": "qulwFIzA7bBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, d_model, nhead, n_encoder, n_decoder, d_mlp, max_len, vocab_size, pad_idx, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "\n",
        "        # Encoder\n",
        "        encoder_layer = EncoderBlock(d_model, nhead, d_mlp, dropout)\n",
        "        encoder_norm = LayerNorm(d_model)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, n_encoder, encoder_norm)\n",
        "\n",
        "\n",
        "        # Decoder\n",
        "        decoder_layer = DecoderBlock(d_model, nhead, d_mlp, dropout)\n",
        "        decoder_norm = LayerNorm(d_model)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, n_decoder, decoder_norm)\n",
        "\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len)\n",
        "\n",
        "        # Embedding layers for input and output\n",
        "        self.input_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
        "        self.output_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
        "\n",
        "\n",
        "        # Final linear layer\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, src, output, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None, is_causal=False):\n",
        "\n",
        "        src = self.input_embedding(src) * np.sqrt(self.d_model)\n",
        "\n",
        "        src = self.pos_encoder(src)\n",
        "\n",
        "        encoder_outputs = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "\n",
        "        output = self.output_embedding(output) * np.sqrt(self.d_model)\n",
        "\n",
        "        output = self.pos_encoder(output)\n",
        "\n",
        "        decoder_outputs = self.decoder(output, encoder_outputs, tgt_mask=tgt_mask, memory_mask=src_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "        outputs = self.linear(decoder_outputs)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "jNFbS0trG0Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "nhead = 1\n",
        "n_encoder_layers = 1\n",
        "n_decoder_layers = 1\n",
        "d_mlp = 1024\n",
        "max_len = 6\n",
        "vocab_size = len(list(\"abcdefghijklmnop\"))\n",
        "pad_idx = 0\n",
        "dropout = 0.1"
      ],
      "metadata": {
        "id": "rlwbw2HuKlkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(d_model, nhead, n_encoder_layers, n_decoder_layers, d_mlp, max_len, vocab_size, pad_idx, dropout)"
      ],
      "metadata": {
        "id": "gSKYgU6gK9wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "cBGgBr1MLK_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReverseDataset(Dataset):\n",
        "    def __init__(self, length=10000, seq_len=10):\n",
        "\n",
        "        self.length = length\n",
        "        self.seq_len = seq_len\n",
        "        self.vocab = list(\"abcdefghijklmnop\")\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.char_to_idx = {char: idx for idx, char in enumerate(self.vocab)}\n",
        "        self.idx_to_char = {idx: char for idx, char in enumerate(self.vocab)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = torch.randint(high=self.vocab_size, size=(self.seq_len,))\n",
        "        return sequence, torch.flip(sequence, dims=[0])\n"
      ],
      "metadata": {
        "id": "xE6FToaysY2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ReverseDataset(seq_len=max_len)\n",
        "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "1sqemawJuPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "model = TransformerModel(d_model, nhead, n_encoder_layers, n_decoder_layers, d_mlp, max_len, vocab_size, pad_idx, dropout).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "v-F6DOMfu2qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(tokens, dataset):\n",
        "    return ''.join(dataset.idx_to_char[token.item()] for token in tokens)"
      ],
      "metadata": {
        "id": "NURfqFeMvQCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = next(iter(dataloader))\n",
        "print(\"Input: \", tokens_to_text(inputs[4], dataset))\n",
        "print(\"Target: \", tokens_to_text(targets[4], dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr9aJYG1wCaF",
        "outputId": "f85d9c66-07d4-4c41-ead5-ef087fac4e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  fifhip\n",
            "Target:  pihfif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (input, target) in enumerate(dataloader):\n",
        "\n",
        "        input = input.T.to(device)\n",
        "        target = target.T.to(device)\n",
        "\n",
        "        taget_input = target[:-1, :]\n",
        "        target_real = target[1:, :]\n",
        "\n",
        "        output = model(input, target_real)\n",
        "\n",
        "        loss = criterion(output.view(-1, vocab_size), target_real.reshape(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dviG3TGuwb3G",
        "outputId": "5e1cd26c-7d84-4768-a791-3f7efca2a4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iteration: 0, Loss: 2.853811740875244\n",
            "Epoch: 0, Iteration: 100, Loss: 0.5882627367973328\n",
            "Epoch: 0, Iteration: 200, Loss: 0.15732300281524658\n",
            "Epoch: 0, Iteration: 300, Loss: 0.07283875346183777\n",
            "Epoch: 0, Iteration: 400, Loss: 0.03663426265120506\n",
            "Epoch: 0, Iteration: 500, Loss: 0.0310231763869524\n",
            "Epoch: 0, Iteration: 600, Loss: 0.01965440809726715\n",
            "Epoch: 0, Iteration: 700, Loss: 0.01606776937842369\n",
            "Epoch: 0, Iteration: 800, Loss: 0.01286899484694004\n",
            "Epoch: 0, Iteration: 900, Loss: 0.009960790164768696\n",
            "Epoch: 0, Iteration: 1000, Loss: 0.009337622672319412\n",
            "Epoch: 0, Iteration: 1100, Loss: 0.007201944477856159\n",
            "Epoch: 0, Iteration: 1200, Loss: 0.006376268342137337\n",
            "Epoch: 0, Iteration: 1300, Loss: 0.005848643369972706\n",
            "Epoch: 0, Iteration: 1400, Loss: 0.0043527306988835335\n",
            "Epoch: 0, Iteration: 1500, Loss: 0.004353075288236141\n",
            "Epoch: 0, Iteration: 1600, Loss: 0.00407132925465703\n",
            "Epoch: 0, Iteration: 1700, Loss: 0.003291928442195058\n",
            "Epoch: 0, Iteration: 1800, Loss: 0.003189435927197337\n",
            "Epoch: 0, Iteration: 1900, Loss: 0.0027617132291197777\n",
            "Epoch: 1, Iteration: 0, Loss: 0.00300198164768517\n",
            "Epoch: 1, Iteration: 100, Loss: 0.0022004293277859688\n",
            "Epoch: 1, Iteration: 200, Loss: 0.0020075496286153793\n",
            "Epoch: 1, Iteration: 300, Loss: 0.0020803872030228376\n",
            "Epoch: 1, Iteration: 400, Loss: 0.001617125584743917\n",
            "Epoch: 1, Iteration: 500, Loss: 0.0016727765323594213\n",
            "Epoch: 1, Iteration: 600, Loss: 0.0013354751281440258\n",
            "Epoch: 1, Iteration: 700, Loss: 0.0014650673838332295\n",
            "Epoch: 1, Iteration: 800, Loss: 0.00129678042139858\n",
            "Epoch: 1, Iteration: 900, Loss: 0.0011487476294860244\n",
            "Epoch: 1, Iteration: 1000, Loss: 0.001045551267452538\n",
            "Epoch: 1, Iteration: 1100, Loss: 0.0010161201935261488\n",
            "Epoch: 1, Iteration: 1200, Loss: 0.0009434251696802676\n",
            "Epoch: 1, Iteration: 1300, Loss: 0.000958934600930661\n",
            "Epoch: 1, Iteration: 1400, Loss: 0.0008577370899729431\n",
            "Epoch: 1, Iteration: 1500, Loss: 0.0007597088697366416\n",
            "Epoch: 1, Iteration: 1600, Loss: 0.0006881158915348351\n",
            "Epoch: 1, Iteration: 1700, Loss: 0.0007374586421065032\n",
            "Epoch: 1, Iteration: 1800, Loss: 0.0006181964417919517\n",
            "Epoch: 1, Iteration: 1900, Loss: 0.0005410053418017924\n",
            "Epoch: 2, Iteration: 0, Loss: 0.0005407571443356574\n",
            "Epoch: 2, Iteration: 100, Loss: 0.00047345628263428807\n",
            "Epoch: 2, Iteration: 200, Loss: 0.0004624318389687687\n",
            "Epoch: 2, Iteration: 300, Loss: 0.0004780855670105666\n",
            "Epoch: 2, Iteration: 400, Loss: 0.00043725865543819964\n",
            "Epoch: 2, Iteration: 500, Loss: 0.0003642816445790231\n",
            "Epoch: 2, Iteration: 600, Loss: 0.0003770169278141111\n",
            "Epoch: 2, Iteration: 700, Loss: 0.0003611275169532746\n",
            "Epoch: 2, Iteration: 800, Loss: 0.00032647783518768847\n",
            "Epoch: 2, Iteration: 900, Loss: 0.0003093949635513127\n",
            "Epoch: 2, Iteration: 1000, Loss: 0.0002835669438354671\n",
            "Epoch: 2, Iteration: 1100, Loss: 0.0002584689937066287\n",
            "Epoch: 2, Iteration: 1200, Loss: 0.0002893107885029167\n",
            "Epoch: 2, Iteration: 1300, Loss: 0.00026668544160202146\n",
            "Epoch: 2, Iteration: 1400, Loss: 0.00023256088024936616\n",
            "Epoch: 2, Iteration: 1500, Loss: 0.00022144900867715478\n",
            "Epoch: 2, Iteration: 1600, Loss: 0.00021832626953255385\n",
            "Epoch: 2, Iteration: 1700, Loss: 0.00019142573000863194\n",
            "Epoch: 2, Iteration: 1800, Loss: 0.00019111107394564897\n",
            "Epoch: 2, Iteration: 1900, Loss: 0.00011932382039958611\n",
            "Epoch: 3, Iteration: 0, Loss: 0.0001621287374291569\n",
            "Epoch: 3, Iteration: 100, Loss: 0.00015633125440217555\n",
            "Epoch: 3, Iteration: 200, Loss: 0.00013924427912570536\n",
            "Epoch: 3, Iteration: 300, Loss: 0.00013678417599294335\n",
            "Epoch: 3, Iteration: 400, Loss: 0.00012736822827719152\n",
            "Epoch: 3, Iteration: 500, Loss: 0.00012665799295064062\n",
            "Epoch: 3, Iteration: 600, Loss: 0.00012128448724979535\n",
            "Epoch: 3, Iteration: 700, Loss: 0.00011195827391929924\n",
            "Epoch: 3, Iteration: 800, Loss: 0.00011214935511816293\n",
            "Epoch: 3, Iteration: 900, Loss: 9.963917545974255e-05\n",
            "Epoch: 3, Iteration: 1000, Loss: 9.598181350156665e-05\n",
            "Epoch: 3, Iteration: 1100, Loss: 9.179588232655078e-05\n",
            "Epoch: 3, Iteration: 1200, Loss: 9.148140088655055e-05\n",
            "Epoch: 3, Iteration: 1300, Loss: 9.066109487321228e-05\n",
            "Epoch: 3, Iteration: 1400, Loss: 7.267155888257548e-05\n",
            "Epoch: 3, Iteration: 1500, Loss: 7.650050247320905e-05\n",
            "Epoch: 3, Iteration: 1600, Loss: 6.828983168816194e-05\n",
            "Epoch: 3, Iteration: 1700, Loss: 6.64972176309675e-05\n",
            "Epoch: 3, Iteration: 1800, Loss: 5.9578764194156975e-05\n",
            "Epoch: 3, Iteration: 1900, Loss: 6.14333912380971e-05\n",
            "Epoch: 4, Iteration: 0, Loss: 6.096161814639345e-05\n",
            "Epoch: 4, Iteration: 100, Loss: 5.535411764867604e-05\n",
            "Epoch: 4, Iteration: 200, Loss: 5.412896643974818e-05\n",
            "Epoch: 4, Iteration: 300, Loss: 4.849298784392886e-05\n",
            "Epoch: 4, Iteration: 400, Loss: 4.340058512752876e-05\n",
            "Epoch: 4, Iteration: 500, Loss: 4.507902485784143e-05\n",
            "Epoch: 4, Iteration: 600, Loss: 4.271404031896964e-05\n",
            "Epoch: 4, Iteration: 700, Loss: 3.954320709453896e-05\n",
            "Epoch: 4, Iteration: 800, Loss: 3.643435047706589e-05\n",
            "Epoch: 4, Iteration: 900, Loss: 3.4293479984626174e-05\n",
            "Epoch: 4, Iteration: 1000, Loss: 3.11273688566871e-05\n",
            "Epoch: 4, Iteration: 1100, Loss: 3.463680695858784e-05\n",
            "Epoch: 4, Iteration: 1200, Loss: 2.999253774760291e-05\n",
            "Epoch: 4, Iteration: 1300, Loss: 2.8948317776666954e-05\n",
            "Epoch: 4, Iteration: 1400, Loss: 2.5901434128172696e-05\n",
            "Epoch: 4, Iteration: 1500, Loss: 2.4871476853149943e-05\n",
            "Epoch: 4, Iteration: 1600, Loss: 2.686937114049215e-05\n",
            "Epoch: 4, Iteration: 1700, Loss: 2.1629042748827487e-05\n",
            "Epoch: 4, Iteration: 1800, Loss: 2.2802043531555682e-05\n",
            "Epoch: 4, Iteration: 1900, Loss: 1.985527887882199e-05\n",
            "Epoch: 5, Iteration: 0, Loss: 2.182932621508371e-05\n",
            "Epoch: 5, Iteration: 100, Loss: 1.8167311282013543e-05\n",
            "Epoch: 5, Iteration: 200, Loss: 1.7576048776390962e-05\n",
            "Epoch: 5, Iteration: 300, Loss: 1.9387993233976886e-05\n",
            "Epoch: 5, Iteration: 400, Loss: 1.6455504010082223e-05\n",
            "Epoch: 5, Iteration: 500, Loss: 1.739485378493555e-05\n",
            "Epoch: 5, Iteration: 600, Loss: 1.2545494428195525e-05\n",
            "Epoch: 5, Iteration: 700, Loss: 1.3866317203792278e-05\n",
            "Epoch: 5, Iteration: 800, Loss: 1.1725340300472453e-05\n",
            "Epoch: 5, Iteration: 900, Loss: 1.3499157830665354e-05\n",
            "Epoch: 5, Iteration: 1000, Loss: 1.0905197086685803e-05\n",
            "Epoch: 5, Iteration: 1100, Loss: 1.1024405466741882e-05\n",
            "Epoch: 5, Iteration: 1200, Loss: 1.0371146345278248e-05\n",
            "Epoch: 5, Iteration: 1300, Loss: 1.0137499884876888e-05\n",
            "Epoch: 5, Iteration: 1400, Loss: 9.002636943478137e-06\n",
            "Epoch: 5, Iteration: 1500, Loss: 8.339842679561116e-06\n",
            "Epoch: 5, Iteration: 1600, Loss: 9.756034160091076e-06\n",
            "Epoch: 5, Iteration: 1700, Loss: 8.521040399500635e-06\n",
            "Epoch: 5, Iteration: 1800, Loss: 7.915464266261552e-06\n",
            "Epoch: 5, Iteration: 1900, Loss: 7.376638677669689e-06\n",
            "Epoch: 6, Iteration: 0, Loss: 6.594633305212483e-06\n",
            "Epoch: 6, Iteration: 100, Loss: 6.661390671069967e-06\n",
            "Epoch: 6, Iteration: 200, Loss: 5.879383479623357e-06\n",
            "Epoch: 6, Iteration: 300, Loss: 6.341912012430839e-06\n",
            "Epoch: 6, Iteration: 400, Loss: 5.755404799856478e-06\n",
            "Epoch: 6, Iteration: 500, Loss: 5.059227078163531e-06\n",
            "Epoch: 6, Iteration: 600, Loss: 5.145057002664544e-06\n",
            "Epoch: 6, Iteration: 700, Loss: 5.354866061679786e-06\n",
            "Epoch: 6, Iteration: 800, Loss: 4.110325789952185e-06\n",
            "Epoch: 6, Iteration: 900, Loss: 4.07694824389182e-06\n",
            "Epoch: 6, Iteration: 1000, Loss: 4.191388597973855e-06\n",
            "Epoch: 6, Iteration: 1100, Loss: 3.986349383922061e-06\n",
            "Epoch: 6, Iteration: 1200, Loss: 3.342621766933007e-06\n",
            "Epoch: 6, Iteration: 1300, Loss: 3.7479323964362266e-06\n",
            "Epoch: 6, Iteration: 1400, Loss: 3.228181185477297e-06\n",
            "Epoch: 6, Iteration: 1500, Loss: 3.8146893075463595e-06\n",
            "Epoch: 6, Iteration: 1600, Loss: 3.0231419714255026e-06\n",
            "Epoch: 6, Iteration: 1700, Loss: 3.1089730327948928e-06\n",
            "Epoch: 6, Iteration: 1800, Loss: 3.0040689580346225e-06\n",
            "Epoch: 6, Iteration: 1900, Loss: 2.51292840403039e-06\n",
            "Epoch: 7, Iteration: 0, Loss: 2.5463064048381057e-06\n",
            "Epoch: 7, Iteration: 100, Loss: 2.6130637706955895e-06\n",
            "Epoch: 7, Iteration: 200, Loss: 2.1123864826222416e-06\n",
            "Epoch: 7, Iteration: 300, Loss: 2.4223293166869553e-06\n",
            "Epoch: 7, Iteration: 400, Loss: 1.8167477264796617e-06\n",
            "Epoch: 7, Iteration: 500, Loss: 2.002713927140576e-06\n",
            "Epoch: 7, Iteration: 600, Loss: 1.9025782194148633e-06\n",
            "Epoch: 7, Iteration: 700, Loss: 1.7213803857885068e-06\n",
            "Epoch: 7, Iteration: 800, Loss: 1.6450863995487452e-06\n",
            "Epoch: 7, Iteration: 900, Loss: 1.4686572740174597e-06\n",
            "Epoch: 7, Iteration: 1000, Loss: 1.5401828932226636e-06\n",
            "Epoch: 7, Iteration: 1100, Loss: 1.4162052366373246e-06\n",
            "Epoch: 7, Iteration: 1200, Loss: 1.3732898196394672e-06\n",
            "Epoch: 7, Iteration: 1300, Loss: 1.3685214526049094e-06\n",
            "Epoch: 7, Iteration: 1400, Loss: 1.1587135304580443e-06\n",
            "Epoch: 7, Iteration: 1500, Loss: 1.1157983408338623e-06\n",
            "Epoch: 7, Iteration: 1600, Loss: 1.0776514045574004e-06\n",
            "Epoch: 7, Iteration: 1700, Loss: 9.727474434839678e-07\n",
            "Epoch: 7, Iteration: 1800, Loss: 8.964535140876251e-07\n",
            "Epoch: 7, Iteration: 1900, Loss: 9.202952924169949e-07\n",
            "Epoch: 8, Iteration: 0, Loss: 8.24928008569259e-07\n",
            "Epoch: 8, Iteration: 100, Loss: 8.344647426383744e-07\n",
            "Epoch: 8, Iteration: 200, Loss: 7.200238769655698e-07\n",
            "Epoch: 8, Iteration: 300, Loss: 7.629391802765895e-07\n",
            "Epoch: 8, Iteration: 400, Loss: 6.914136747582234e-07\n",
            "Epoch: 8, Iteration: 500, Loss: 7.343290917560807e-07\n",
            "Epoch: 8, Iteration: 600, Loss: 6.341932703435305e-07\n",
            "Epoch: 8, Iteration: 700, Loss: 6.103514351707418e-07\n",
            "Epoch: 8, Iteration: 800, Loss: 5.960462772236497e-07\n",
            "Epoch: 8, Iteration: 900, Loss: 6.294249033089727e-07\n",
            "Epoch: 8, Iteration: 1000, Loss: 4.6730033886888123e-07\n",
            "Epoch: 8, Iteration: 1100, Loss: 4.5776360479976574e-07\n",
            "Epoch: 8, Iteration: 1200, Loss: 4.386901366615348e-07\n",
            "Epoch: 8, Iteration: 1300, Loss: 3.957748049288057e-07\n",
            "Epoch: 8, Iteration: 1400, Loss: 4.3869010823982535e-07\n",
            "Epoch: 8, Iteration: 1500, Loss: 3.6239620726519206e-07\n",
            "Epoch: 8, Iteration: 1600, Loss: 3.4332271070525167e-07\n",
            "Epoch: 8, Iteration: 1700, Loss: 3.0994411304163805e-07\n",
            "Epoch: 8, Iteration: 1800, Loss: 3.6239620726519206e-07\n",
            "Epoch: 8, Iteration: 1900, Loss: 3.0040737897252257e-07\n",
            "Epoch: 9, Iteration: 0, Loss: 3.2901760960157844e-07\n",
            "Epoch: 9, Iteration: 100, Loss: 2.7656554379973386e-07\n",
            "Epoch: 9, Iteration: 200, Loss: 2.6702878130890895e-07\n",
            "Epoch: 9, Iteration: 300, Loss: 2.4795528474896855e-07\n",
            "Epoch: 9, Iteration: 400, Loss: 1.8119810363259603e-07\n",
            "Epoch: 9, Iteration: 500, Loss: 1.9073485191256623e-07\n",
            "Epoch: 9, Iteration: 600, Loss: 2.098083342616519e-07\n",
            "Epoch: 9, Iteration: 700, Loss: 2.2411344957617985e-07\n",
            "Epoch: 9, Iteration: 800, Loss: 1.6212462128351035e-07\n",
            "Epoch: 9, Iteration: 900, Loss: 1.8119810363259603e-07\n",
            "Epoch: 9, Iteration: 1000, Loss: 1.7166135535262583e-07\n",
            "Epoch: 9, Iteration: 1100, Loss: 1.8119810363259603e-07\n",
            "Epoch: 9, Iteration: 1200, Loss: 1.9073485191256623e-07\n",
            "Epoch: 9, Iteration: 1300, Loss: 1.5258788721439487e-07\n",
            "Epoch: 9, Iteration: 1400, Loss: 1.2874602361989673e-07\n",
            "Epoch: 9, Iteration: 1500, Loss: 1.2874602361989673e-07\n",
            "Epoch: 9, Iteration: 1600, Loss: 1.1920928244535389e-07\n",
            "Epoch: 9, Iteration: 1700, Loss: 9.536742595628311e-08\n",
            "Epoch: 9, Iteration: 1800, Loss: 9.059905181629802e-08\n",
            "Epoch: 9, Iteration: 1900, Loss: 9.059905181629802e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def output_to_text(output, dataset):\n",
        "\n",
        "    tokens = F.softmax(output, dim=-1)\n",
        "\n",
        "    tokens = torch.argmax(tokens, dim=-1)\n",
        "\n",
        "    text = ''.join(dataset.idx_to_char[token.item()] for token in tokens)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "UDzaaAZCzMUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = next(iter(dataloader))\n",
        "\n",
        "index = 1\n",
        "\n",
        "print(\"Input: \", tokens_to_text(inputs[index], dataset))\n",
        "print(\"Target: \", tokens_to_text(targets[index], dataset))\n",
        "\n",
        "input = inputs[index].T.to(device)\n",
        "target = targets[index].T.to(device)\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtl5FBGt51ju",
        "outputId": "33be52e4-6fe0-468e-e476-12e801790919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  nbpoac\n",
            "Target:  caopbn\n",
            "tensor([ 2,  0, 14, 15,  1, 13], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input, target)"
      ],
      "metadata": {
        "id": "uvOA_9FY6VaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \", tokens_to_text(inputs[index], dataset))\n",
        "print(\"Prediction: \", output_to_text(output[index], dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2wphQwD6Zj2",
        "outputId": "202d20f5-8388-4e27-c8c1-af46b3ec2025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  nbpoac\n",
            "Prediction:  caopbn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2tc2wexI7BuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}